{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib  # Para guardar y cargar los modelos\n",
    "import numpy as np  # Para trabajo de datos numéricos\n",
    "import pandas as pd  # Para manipulación y análisis de los datos\n",
    "\n",
    "# Scikit-Learn\n",
    "from sklearn.ensemble import RandomForestClassifier # Modelo de ML\n",
    "from sklearn.metrics import classification_report # Para ver resultados del modelo\n",
    "from sklearn.model_selection import train_test_split # Para división de datos de entrenamiento y prueba\n",
    "from sklearn.preprocessing import RobustScaler # Para escalar los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar datos con fallas ficticias\n",
    "df = pd.read_csv(\"datos_con_fallas_sinteticas_vf.csv\")\n",
    "\n",
    "# Lista de sensores para definir falla\n",
    "sensores = [\n",
    "    'CNN-3200-CR_0001_MO.PWR',\n",
    "    'CNN-3200-CR_0001_MO.CUR',\n",
    "    'CNN-3200-FIT32053.PV',\n",
    "    'CNN-3200-FIT32054.PV',\n",
    "    'CNN-3200-PIT32031.PV',\n",
    "    'CNN-3200-PIT32043.PV',\n",
    "    'CNN-3200-PIT32056.PV',\n",
    "    'CNN-3200-TIT32045.PV',\n",
    "    'CNN-3200-TIT32046.PV'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "target = 'Posible_Falla'\n",
    "\n",
    "for sensor in sensores:\n",
    "    sensor_std = f\"{sensor}_std\"\n",
    "    nombre = sensor.replace('.', '_')  # Para guardar los archivos del modelo de cada sensor\n",
    "\n",
    "    print(f\"\\n... Entrenando modelo para: {sensor} ...\")\n",
    "\n",
    "    # Extraer datos del sensor y su std\n",
    "    X = df[[sensor, sensor_std]].copy()\n",
    "    y = df[target].copy()\n",
    "\n",
    "    # Escalar datos\n",
    "    scaler = RobustScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Guardar el scaler con el nombre del sensor correspondiente\n",
    "    joblib.dump(scaler, f\"scaler_{nombre}.pkl\")\n",
    "\n",
    "    # División de datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Entrenamiento del modelo \n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Guardar el modelo con el nombre del sensor correspondiente\n",
    "    joblib.dump(rf, f\"modelo_{nombre}.pkl\")\n",
    "\n",
    "    # Evaluación del modelo actual\n",
    "    y_pred = rf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
